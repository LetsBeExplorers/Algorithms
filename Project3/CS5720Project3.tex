\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{listings}
\usepackage{caption}
\captionsetup{font=small, labelfont=bf, labelsep=colon}

\lstset{
    breaklines=true
}

\title{CS 5720 Project 3: Knapsack Problem Analysis}
\author{Rachel Koch}
\date{\today}

\begin{document}
\maketitle

\section{Attributions}

ChatGPT file changes: \textit{main.py}

\begin{quote}
\textbf{Overall Code Changes} \\
Changed the name of the file\\
Imported random and sys library \\
Reorganized code so it is in order of deliverable \\
Deliverable 2 times/graphs multiple combos of fixed variables \\
Split the deliverable 2 timer code into two functions: test and measure \\
Added messages about successful completion of events \\
Measure exec time low weights function reworked to be more like deliverable 2 \\
Low weights plot function no longer applies - reused previous plotting functions

\textbf{New Functions} \\
Added verificationTest function \\
Added newIntArray function \\
Added newIntArrayCeiling function \\
Added test\_execution\_times() \\
Added plot\_performance\_fixedW() function \\
Added plot\_performance\_fixedn() function \\
Added test\_execution\_times\_smallwts() function

\textbf{File Management} \\
Verification test results are written to a file \\
Multiple plots are generated

\textbf{knapsack\_bottom\_up() function} \\
Added a check for zero size or zero capacity knapsack \\
Added comments

\textbf{knapsack\_top\_down() function} \\
Function now takes a size argument \\
Renamed variables and helper function \\
Renamed and added arguments for helper function \\
Reordered return and assignment statements \\
Initialized array with -1's instead of empty \\
Added comments

\textbf{measure\_execution\_times() function}\\
Changed name to test instead of measure \\
Factored out all timer code to another function \\
Changed format so function handles fixed $n$ or $W$ \\
Added two branches that process differently based on fixed variable \\
Random arrays are generated by a new function

\textbf{plot\_random\_inputs\_performance() function}\\
Split function to graph differently for fixed W/n \\
Removed line style and marker type - so lines are colored \\
Plots all of range for x and fixed values for y \\
Plot and file names include fixed number \\
Different file names and titles for small weights

\textbf{measure\_execution\_time\_representation() function} \\
Factored out the timer into new function 

\end{quote}
ChatGPT file changes: \textit{project3.tex}

\begin{quote}
Changed the name of the file\\
Replaced all plots \\
New code in Deliverable 1 section \\
Allowed line breaking for code snippets \\
Added subsection for verification test results in Deliverable 1 \\
Added runtime analysis to Deliverable 1 \\
Deliverable 2 has multiple plots showing fixed $W$/fixed $n$ \\
Added discussions to Deliverable 2 section about the plots \\
Added additional discussion for Deliverable 3

\end{quote}

\section*{Introduction}
This report explores the performance of two dynamic programming algorithms for solving the Knapsack problem: the bottom-up approach and the top-down approach with memoization. Performance comparisons are provided under various conditions, including random and low-weight inputs, and an illustration of the pseudopolynomial-time complexity.

\section{Deliverable 1: Code Implementation and Verification of Correctness}
\subsection{Code for Bottom-Up Dynamic Programming Approach}
\begin{lstlisting}[language=Python]
def knapsack_bottom_up(weights, values, capacity):
    n = len(weights)
    dp = [[0 for i in range(capacity + 1)] for j in range(n + 1)]
    
    # check all items
    for i in range(1, n + 1):
        for w in range(capacity + 1):
            # check case for zero size or zero capacity knapsack
            if i == 0 or w == 0:
                dp[i][w] = 0
            # if there is enough room, choose whether to take the new item or not
            elif weights[i - 1] <= w:
                dp[i][w] = max(dp[i - 1][w], dp[i - 1][w - weights[i - 1]] + values[i - 1])
            # if not enough room, skip item
            else:
                dp[i][w] = dp[i - 1][w]
    
    return dp[n][capacity]
\end{lstlisting}

\subsection{Code for Top-Down Dynamic Programming Approach}
\begin{lstlisting}[language=Python]
def knapsack_top_down(weights, values, capacity, n):
    # initialize the matrix with -1
    memo = [[-1 for i in range(capacity + 1)] for j in range(n + 1)]

    def knapsack(wts, val, capacity, n): 
        # base conditions
        # size zero knapsack or no capacity
        if n == 0 or capacity == 0:
            return 0
        # solution already exists
        if memo[n][capacity] != -1:
            return memo[n][capacity]

        # if enough room, chose whether to take the item or not
        if wts[n - 1] <= capacity:
            memo[n][capacity] = max(val[n - 1] + knapsack(wts, val, capacity - wts[n - 1], n - 1), knapsack(wts, val, capacity, n - 1))
            return memo[n][capacity]
        # if not enough room, skip the item
        elif wts[n - 1] > capacity:
            memo[n][capacity] = knapsack(wts, val, capacity, n - 1)
            return memo[n][capacity]

    return knapsack(weights, values, capacity, n)
\end{lstlisting}

\subsection{Verification}
Verification test results can be found in a file named \textit{test.txt}. Each test generated an array of random weights, values, and a random capacity. Then it compared the results of the Bottom-Up algorithm and the Top-Down algorithm, indicating a pass/fail. Testing showed that the the algorithm results matched in every case. By the end of this project, over 150 tests had been performed and they all passed. A small subset of the results are shown below. \\ \\
\ttfamily
Verification Test \\
Weights:  [5, 5, 7, 8, 8, 10, 10, 2, 7] \\
Values:  [4, 4, 5, 9, 5, 10, 7, 10, 5]\\
Capacity:  33\\
Passed\\
Bottom-Up =  38 \\
Top-Down =  38 \\
 \\
Verification Test \\
Weights:  [10, 9, 7, 2, 2] \\
Values:  [9, 8, 8, 7, 7] \\
Capacity:  14 \\
Passed \\
Bottom-Up =  23 \\
Top-Down =  23 \\
\\
Verification Test \\
Weights:  [6, 9, 10] \\
Values:  [2, 6, 10] \\
Capacity:  32 \\
Passed \\
Bottom-Up =  18 \\
Top-Down =  18 \\
 \\
Verification Test \\
Weights:  [10, 5] \\
Values:  [5, 8] \\
Capacity:  32 \\
Passed \\
Bottom-Up =  13 \\
Top-Down =  13 \\
\\
Verification Test \\
Weights:  [4, 8, 4, 7, 3, 4, 3] \\
Values:  [5, 2, 6, 2, 5, 1, 7] \\
Capacity:  0 \\
Passed \\
Bottom-Up =  0 \\
Top-Down =  0 \\
\\
\rmfamily
Additional test results are appended to the original \textit{test.txt} file every time the program is run, so testing can be independently verified. Screenshots are included to show that the file contained 170 passed tests and no failed tests. 
    \begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Screenshot from 2024-11-17 12-48-51.png}
	\caption{Screenshot showing 170 passed tests.}
    \end{figure}
    
    \begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Screenshot from 2024-11-17 12-49-01.png}
	\caption{Screenshot showing 0 failed tests.}
    \end{figure}

\subsection{Run-Time Analysis}
Both the Bottom-Up and Top-Down approaches have a runtime of $\Theta(nW)$ where $W$ is the capacity. By examining the code in section 2.1, we can see that the Bottom-Up approach has two nested loops - the outside loop will run $n$ times, and the inside loop will run $W$ (capacity) times. This verifies that the algorithm has a runtime of $\Theta(nW)$. Examining the code in section 2.2 for the Top-Down approach, we can see that the table being filled out is size $n$ x $W$ (capacity). If comparison is the main operation, then it gets performed for every cell, making the runtime also $\Theta(nW)$.  

\newpage
\section{Deliverable 2: Performance Comparison with Random Inputs}
\subsection{Plots of Execution Times for Fixed Capacity}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedW_50.png}
    \caption{Execution times of Knapsack algorithms with fixed Capacity of 50 and n = 1 to 100.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedW_250.png}
    \caption{Execution times of Knapsack algorithms with fixed Capacity of 250 and n = 1 to 100.}
\end{figure}

\newpage
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedW_500.png}
    \caption{Execution times of Knapsack algorithms with fixed Capacity of 500 and n = 1 to 100.}
\end{figure}

\subsection{Fixed Capacity Discussion}
As can be seen in Figures 1, 2, and 3, the runtime for our top-down algorithm stayed faster than our bottom-up algorithm until large $n$. Once $n$ began to approach 80, the top-down runtime more than doubled. Additionally, for large $n$, the gap between runtimes of both algorithms widened significantly, on average. \\
\textit{Note:} There is an anomaly in Figure 1 for $n$ around 55, but I couldn't figure out why. I assume it has something to do with my computer's cache. 

\subsection{Plots of Execution Times for Fixed n}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_10.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 10 and capacity = 50 to 500.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_25.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 25 and capacity = 50 to 500.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_50.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 50 and capacity = 50 to 500.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_100.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 100 and capacity = 50 to 500.}
\end{figure}

\subsection{Fixed n Discussion}
As can be seen in Figures 4 and 5, the runtime for our top-down algorithm stayed faster than our bottom-up algorithm across all capacity values for smaller $n$. The gap between runtimes was also much more significant for smaller values of $n$. In Figure 6, the runtimes were much closer and occasionally crossed each other, despite the top-down algorithm generally being faster. By Figure 7, the largest value of $n$, we see that the top-down algorithm is much slower than the bottom-up approach.

\subsection{Further Discussion}
The Figures in section 3.1 - i.e. Figures 1, 2, and 3 - give the impression that capacity has very little effect on the difference between runtimes for both approaches. Across all three figures, this difference stays small until large $n$, where it more than doubles. The Figures in section 3.3 - i.e. Figures 4, 5, 6, and 7 - lead to the same conclusion; the size of $n$ has more affect on the performance gap than capacity. As a concrete example, Figure 4 - small $n$ - shows the difference between runtimes is approximately 0.002. Whereas in Figure 7 - largest $n$  - the difference is about 0.0075.

I think the reason our top-down approach is slower than our bottom-up approach for large $n$ - and has a bigger performance gap - is because of the overhead on recursive calls. For large $n$, i.e. more items, the overhead of checking for previously solved sub-problems is compounding and slows down the entire algorithm. Alternatively, in the bottom-up approach our work is much more linear, it just fills out the table by checking to see if some previous combination was more valuable given the space. 

In contrast, the capacity of the Knapsack doesn't change how many comparisons we have to make, so it doesn't really change the runtime.

\newpage
\section{Deliverable 3: Performance Comparison with Low Weights}
\subsection{Plots of Execution Times for Fixed Capacity with Low-Weight Inputs}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedW_50_smallwts.png}
    \caption{Execution times of Knapsack algorithms with fixed Capacity of 50 and n = 1 to 100 with small weights.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedW_250_smallwts.png}
    \caption{Execution times of Knapsack algorithms with fixed Capacity of 250 and n = 1 to 100 with small weights.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedW_500_smallwts.png}
    \caption{Execution times of Knapsack algorithms with fixed Capacity of 500 and n = 1 to 100 with small weights.}
\end{figure}
\newpage
\subsection{Plots of Execution Times for Fixed n with Low-Weight Inputs}

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_10_smallwts.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 10 and capacity = 50 to 500 with small weights.}
\end{figure}
\newpage
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_25_smallwts.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 25 and capacity = 50 to 500 with small weights.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_50_smallwts.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 50 and capacity = 50 to 500 with small weights.}
\end{figure}
\newpage
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_fixedn_100_smallwts.png}
    \caption{Execution times of Knapsack algorithms with fixed n of 100 and capacity = 50 to 500 with small weights.}
\end{figure}

\subsection{Discussion}
With low-weight inputs, both algorithms performed more slowly overall than in section 3. Additionally, both algorithms performed more closely due to the reduced complexity in the number of potential sub-problems. The gaps in Figures 8 through 14 \textit{appear} similar to those in the Figures from section 3 [Figures 1 through 7] at first glance, but upon further examination of the y-axis, it can be seen that the performance gaps are smaller. However, performance of both algorithms compared to each other did not change, and showed the same behavior as from Section 3.  

\newpage
\section{Deliverable 4: Illustration of Pseudopolynomial-Time Complexity}
\subsection{Plot of Pseudopolynomial-Time Complexity}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plot_pseudopolynomial.png}
    \caption{Illustration of pseudopolynomial-time complexity by plotting runtime versus representation size of \( W \).}
\end{figure}

\subsection{Discussion}
The pseudopolynomial nature of the algorithms is evident in Figure 15, as runtime scales with the magnitude of \( W \) rather than its binary size. This behavior emphasizes the limitations of dynamic programming solutions for large \( W \).

\section*{Conclusion}
This project successfully compared two dynamic programming approaches to the Knapsack problem under various input scenarios, highlighting differences in execution time and the implications of pseudopolynomial complexity.

\end{document}